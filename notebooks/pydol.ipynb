{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jack3690/pydol/blob/main/notebooks/pydol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdotZvxJpGb-"
      },
      "source": [
        "# **Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i7obQzlwD77"
      },
      "outputs": [],
      "source": [
        "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline\n",
        "import jwst.associations\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "import os\n",
        "from crds import client\n",
        "import jwst\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "\n",
        "crds_dir = Path(__file__).parent.joinpath('CRDS')/'crds_cache'\n",
        "os.makedirs(crds_dir, exist_ok=True)\n",
        "os.environ['CRDS_PATH'] = str(crds_dir)\n",
        "os.environ[\"CRDS_SERVER_URL\"] = \"https://jwst-crds.stsci.edu\"\n",
        "client.set_crds_server(\"https://jwst-crds.stsci.edu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wdueubA3wF_a"
      },
      "outputs": [],
      "source": [
        "class jpipe():\n",
        "    def __init__(self, input_files=[], out_dir='.',\n",
        "                 crds_context=\"jwst_1241.pmap\"):\n",
        "        \"\"\"\n",
        "            Parameters\n",
        "            ----------\n",
        "            input_files: list,\n",
        "                         Input list of level 0 '_uncal.fits' files. \n",
        "                         Recommended: /data/stage0/\n",
        "            out_dir: str,\n",
        "                     Output directory. \n",
        "                     Recommended: The directory that contains /data/stage0/\n",
        "                     Pipeline will create /data/stage1/ and /data/stage2/\n",
        "                     \n",
        "            crds_context: str,\n",
        "                          Reference context for JWST pipeline from CRDS.\n",
        "\n",
        "              Returns\n",
        "              -------\n",
        "                  None\n",
        "                        \n",
        "        \"\"\"\n",
        "        if len(input_files)<1:\n",
        "            raise Exception(\"Input files list CANNOT be empty!\")\n",
        "        self.input_files = input_files\n",
        "        self.out_dir = out_dir\n",
        "        os.makedirs(out_dir + '/data/stage1/', exist_ok=True)\n",
        "        os.makedirs(out_dir + '/data/stage2/', exist_ok=True)\n",
        "        os.environ[\"CRDS_CONTEXT\"] = crds_context\n",
        "\n",
        "    def stage1(self, filename):\n",
        "        \"\"\"\n",
        "            Parameters\n",
        "            ----------\n",
        "            filename: str,\n",
        "                      path to the level 0 \"_uncal.fits\" file\n",
        "            Returns\n",
        "            -------\n",
        "                None\n",
        "        \"\"\"\n",
        "        # Instantiate the pipeline\n",
        "        img1 = Detector1Pipeline()\n",
        "        # Specify where the output should go\n",
        "        img1.output_dir = self.out_dir + '/data/stage1/'\n",
        "        # Save the final resulting _rate.fits files\n",
        "        img1.save_results = True\n",
        "        #No of cores\n",
        "        img1.jump.maximum_cores = f'{mp.cpu_count()-1}'\n",
        "        # Run the pipeline on an input list of files\n",
        "        img1(filename)\n",
        "        \n",
        "    def stage2(self, filename):\n",
        "        \"\"\"\n",
        "            Parameters\n",
        "            ----------\n",
        "            filename: str,\n",
        "                      path to the level 1 \"_rate.fits\" file\n",
        "            Returns\n",
        "            -------\n",
        "                None\n",
        "        \"\"\"\n",
        "        # Instantiate the pipeline\n",
        "        img2 = Image2Pipeline()\n",
        "        # Specify where the output should go\n",
        "        img2.output_dir = self.out_dir + '/data/stage2/'\n",
        "        # Save the final resulting _rate.fits files\n",
        "        img2.save_results = True\n",
        "        # Run the pipeline on an input list of files\n",
        "        img2(filename)\n",
        "\n",
        "    def __call__(self):\n",
        "        \"\"\"\n",
        "            Runs the JWST Stage 1 and Stage 2 pipeline for generating\n",
        "            '_cal.fits' files\n",
        "        \"\"\"\n",
        "        uncal_files = [i for i in self.input_files if 'uncal' in i ]\n",
        "        for f in uncal_files:\n",
        "            o = f.replace('stage0','stage1')\n",
        "            o = o.replace('uncal','rate')\n",
        "            if not os.path.exists(o):\n",
        "                self.stage1(f)\n",
        "\n",
        "        rate_files = glob(self.out_dir + '/data/stage1/*_rate.fits')\n",
        "        rate_files_ = []\n",
        "        for f in rate_files:\n",
        "            o = f.replace('stage1','stage2')\n",
        "            o = o.replace('rate','cal')\n",
        "            if not os.path.exists(o):\n",
        "                rate_files_.append(f)\n",
        "            \n",
        "        if len(rate_files_)>0:\n",
        "            with mp.Pool(mp.cpu_count()-1) as p:\n",
        "                p.map(self.stage2, rate_files_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Photometry**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from astropy.table import Table\n",
        "from astropy.wcs import WCS\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "param_dir = str(Path(__file__).parent.joinpath('params'))\n",
        "script_dir = str(Path(__file__).parent.joinpath('scripts'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def nircam_phot(cal_files, name='f200w',output_dir='.', drz_path='.', ):\n",
        "    subprocess.run([\"nircammask\", f\"{drz_path}.fits\"], shell=True) \n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # Generating directories\n",
        "    exps = []\n",
        "    for i,f in enumerate(cal_files):\n",
        "        out_dir = f.split('/')[-1].split('.')[0]\n",
        "\n",
        "        if not os.path.exists(f'{output_dir}/{out_dir}'):\n",
        "            os.mkdir(f'{output_dir}/{out_dir}')\n",
        "        if not os.path.exists(f\"{output_dir}/{out_dir}/data.fits\"):\n",
        "            subprocess.run([\"cp\", f\"{f}\", f\"{output_dir}/{out_dir}/data.fits\"], shell=True)\n",
        "\n",
        "        exps.append(f'{output_dir}/{out_dir}')\n",
        "\n",
        "    # Applying NIRCAM Mask\n",
        "    for f in exps:\n",
        "        if not os.path.exists(f\"{f}/data.sky.fits\"):\n",
        "            subprocess.run([\"nircammask\", f\"{f}/data.fits\"], shell=True)\n",
        "            subprocess.run([\"calcsky\", f\"{f}/data\", \"10\", \"25\", \"2\", \"2.25\", \"2.00\"], shell=True)\n",
        "\n",
        "    # Preparing Parameter file DOLPHOT NIRCAM\n",
        "    with open(f\"{param_dir}/nircam_dolphot.param\") as f:\n",
        "                dat = f.readlines()\n",
        "\n",
        "    dat[0] = f'Nimg = {len(exps)}                #number of images (int)\\n'\n",
        "    dat[4] = f'img0_file = {drz_path}\\n'\n",
        "\n",
        "    for i,f in enumerate(exps):\n",
        "        dat[5+i] = f'img{i+1}_file = {f}/data           #image {i+1}\\n'\n",
        "\n",
        "    out_id = np.random.random()\n",
        "    with open(f\"{param_dir}/nircam_dolphot_{out_id}.param\", 'w', encoding='utf-8') as f:\n",
        "        f.writelines(dat)\n",
        "        \n",
        "    if not os.path.exists(f\"{output_dir}/{name}_photometry.fits\"):\n",
        "        # Running DOLPHOT NIRCAM\n",
        "         subprocess.run([\"dolphot\", f\"{output_dir}/out\", f\"-p{param_dir}/nircam_dolphot_{out_id}.param\"], shell=True)\n",
        "\n",
        "    # Generating Astropy FITS Table\n",
        "   \n",
        "    subprocess.run([\"python\", f\"{script_dir}to_table.py\", \"--o\", f\"{name}_photometry\", \"--n\", f\"{len(exps)}\", \"--f\", f\"{output_dir}/out\"])\n",
        "\n",
        "    phot_table = Table.read(f\"{output_dir}/{name}_photometry.fits\")\n",
        "    phot_table.rename_columns(['mag_vega'],[f'mag_vega_F200W'])\n",
        "\n",
        "    # Assingning RA-Dec using reference image\n",
        "    hdu = fits.open(f\"{drz_path}.fits\")[1]\n",
        "\n",
        "    wcs = WCS(hdu.header)\n",
        "    positions = np.transpose([phot_table['x'] - 0.5, phot_table['y']-0.5])\n",
        "\n",
        "    coords = np.array(wcs.pixel_to_world_values(positions))\n",
        "\n",
        "    phot_table['ra']  = coords[:,0]\n",
        "    phot_table['dec'] = coords[:,1]\n",
        "\n",
        "    # Filtering stellar photometry catalog using Warfield et.al (2023)\n",
        "    phot_table1 = phot_table[ (phot_table['sharpness']**2   <= 0.01) &\n",
        "                                (phot_table['obj_crowd']    <=  0.5) &\n",
        "                                (phot_table['flags']        <=    2) &\n",
        "                                (phot_table['type']         <=    2)]\n",
        "\n",
        "    phot_table2 = phot_table[ ~((phot_table['sharpness']**2 <= 0.01) &\n",
        "                                (phot_table['obj_crowd']    <=  0.5) &\n",
        "                                (phot_table['flags']        <=    2) &\n",
        "                                (phot_table['type']         <=    2))]\n",
        "    print('NIRCAM SHORT')\n",
        "    phot_table.write(f'{output_dir}/{name}_photometry.fits', overwrite=True)\n",
        "    phot_table1.write(f'{output_dir}/{name}_photometry_filt.fits', overwrite=True)\n",
        "    phot_table2.write(f'{output_dir}/{name}_photometry_rej.fits', overwrite=True)\n",
        "    \n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
